{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import en_vectors_web_lg\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "from shared.data import load_imdb\n",
    "from machine_learning.plot_helpers import describe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_vectors_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data...\")\n",
    "X_train, y_train = load_imdb('../data/aclImdb/train')\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "X_test, y_test = load_imdb('../data/aclImdb/test')\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'text': pd.Series(X_train + X_test),\n",
    "    'score': pd.Series(y_train[:, 0] + y_test[:, 0])\n",
    "})\n",
    "\n",
    "del X_train\n",
    "del y_train\n",
    "del X_test\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(text_series):\n",
    "    for sentence in text_series:\n",
    "        for t in nlp(sentence):\n",
    "            if t and t.lemma_:\n",
    "                yield t.lemma_.lower()\n",
    "\n",
    "words = pd.Series(generate_words(data.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Total words**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13377116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Unique words**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "172778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = words.value_counts()\n",
    "\n",
    "display_markdown(\"**Total words**\", raw=True)\n",
    "display(len(words))\n",
    "\n",
    "display_markdown(\"**Unique words**\", raw=True)\n",
    "display(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Let's print the most popular words**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "the      648550\n",
       ",        542712\n",
       "be       483885\n",
       ".        449595\n",
       "a        445083\n",
       "and      321829\n",
       "of       288816\n",
       "to       267857\n",
       "have     240375\n",
       "in       183748\n",
       "it       151203\n",
       "that     147998\n",
       "this     147662\n",
       "i        136770\n",
       "\"        136634\n",
       "-        103536\n",
       "/><br    100972\n",
       "movie     99224\n",
       "not       92185\n",
       "film      91615\n",
       "with      86640\n",
       "for       86247\n",
       "but       81610\n",
       "on        67151\n",
       "(         64951\n",
       ")         63982\n",
       "much      62011\n",
       "you       59333\n",
       "his       57406\n",
       "do        53902\n",
       "one       53028\n",
       "he        52252\n",
       "see       46666\n",
       "good      46660\n",
       "at        46189\n",
       "make      45321\n",
       "all       45294\n",
       "by        44099\n",
       "like      43806\n",
       "can       42427\n",
       "'         41811\n",
       "they      41558\n",
       "who       40960\n",
       "from      40048\n",
       "!         39889\n",
       "so        39410\n",
       "get       35214\n",
       "or        35183\n",
       "just      34700\n",
       "her       34440\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(\"**Let's print the most popular words**\", raw=True)\n",
    "display(counts[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Ok, we want to remove all stopwords and punctuations**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Total cleaned words**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'4831723 - 36.12% of all'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Unique cleaned words**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "82333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Let's print the most popular words**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "movie          99232\n",
       "film           91610\n",
       "good           46661\n",
       "like           43807\n",
       "time           30344\n",
       "character      27235\n",
       "watch          26668\n",
       "story          24432\n",
       "think          24131\n",
       "little         22007\n",
       "scene          20840\n",
       "great          19599\n",
       "look           19485\n",
       "know           18834\n",
       "end            18035\n",
       "bad            17950\n",
       "people         17767\n",
       "play           16937\n",
       "love           16826\n",
       "act            16790\n",
       "way            16682\n",
       "come           16170\n",
       "thing          15825\n",
       "find           15784\n",
       "br             15747\n",
       "conjurer       15209\n",
       "man            14358\n",
       "work           13426\n",
       "plot           13422\n",
       "actor          13042\n",
       "want           13026\n",
       "life           12377\n",
       "try            12303\n",
       "feel           12265\n",
       "year           12129\n",
       "doe            11114\n",
       "wrong          11078\n",
       "old            10121\n",
       "use             9860\n",
       "funny           9447\n",
       "lot             9347\n",
       "real            9311\n",
       "interest        9270\n",
       "director        9235\n",
       "guy             8858\n",
       "performance     8789\n",
       "cast            8425\n",
       "big             8391\n",
       "leave           8380\n",
       "actually        8350\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "display_markdown(\"**Ok, we want to remove all stopwords and punctuations**\", raw=True)\n",
    "cleaned_words = pd.Series([w for w in words if w.lower() not in STOP_WORDS and w.isalpha()])\n",
    "\n",
    "display_markdown(\"**Total cleaned words**\", raw=True)\n",
    "display('{} - {:.2f}% of all'.format(len(cleaned_words), len(cleaned_words) * 1.0 / len(words) * 100))\n",
    "\n",
    "cleaned_counts = cleaned_words.value_counts()\n",
    "display_markdown(\"**Unique cleaned words**\", raw=True)\n",
    "display(len(cleaned_counts))\n",
    "\n",
    "display_markdown(\"**Let's print the most popular words**\", raw=True)\n",
    "display(cleaned_counts[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Time to remove all words that we saw only once, as they won't help us to teach models**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Out final words statistics looks like this**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'48758 - 59.22% of words'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(\"**Time to remove all words that we saw only once, as they won't help us to teach models**\", raw=True)\n",
    "final_words = cleaned_counts[cleaned_counts > 1].index.values\n",
    "\n",
    "display_markdown(\"**Out final words statistics looks like this**\", raw=True)\n",
    "display('{} - {:.2f}% of words'.format(len(final_words), len(final_words) * 1.0 / len(cleaned_counts) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Let's clean datasets**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(\"**Let's clean datasets**\", raw=True)\n",
    "\n",
    "allowed_words = set(final_words)\n",
    "\n",
    "def clean(sentence):\n",
    "    return ' '.join(t.lemma_.lower() for t in nlp(sentence) if t and t.lemma_ and t.lemma_.lower() in allowed_words) \n",
    "\n",
    "data['cleaned'] = data.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        katzir produce wonderful film roller coaster r...\n",
       "1        want scream like big studio horror product for...\n",
       "2        premise rate low plausibility unfortunately co...\n",
       "3        face rent stdvd sequel forget gem expect afore...\n",
       "4        tobe hooper exercise regard unfortunate young ...\n",
       "5        maybe pc version game impressive maybe finish ...\n",
       "6        kroko like leave cinema time life recommend wa...\n",
       "7        start comment huge nightmare elm street fan th...\n",
       "8        film time extremely long sequence dialogue bad...\n",
       "9        invisible ray science fiction horror conjurer ...\n",
       "10       touch story courage adversity woman find jewis...\n",
       "11       shipman pay hefty sum money promote maxwell ro...\n",
       "12       sundance movie certainly miss real art house d...\n",
       "13       bother try watch terrible mini series hour bea...\n",
       "14       parent male able identify character heartache ...\n",
       "15       story grow relationship jeff stewart ronda rom...\n",
       "16       weekend watch funny film like kid cute remind ...\n",
       "17       film tell story romance albert einstien niece ...\n",
       "18       like movie sort remind marriage clean family n...\n",
       "19       gringo telly savalas frank cooper mexico borde...\n",
       "20       main reason write review find great play worth...\n",
       "21       alert movie watch fail fit tribute magnificent...\n",
       "22       wonderful surprise spanish cinema think jordi ...\n",
       "23       doe come leave field expect love memorable mov...\n",
       "24       love proper anchorman film bad kind bad wish t...\n",
       "25       enjoy movie movie come relate movie kid let kn...\n",
       "26       truly unpleasant film rick baker special effec...\n",
       "27       little episode tv series string usual commerci...\n",
       "28       let like fact rock win title gay feel regal eu...\n",
       "29       far b movie scarecrow bad incredibly annoy sit...\n",
       "                               ...                        \n",
       "24970    writer producer director charles band responsi...\n",
       "24971    screen movie time college time numb people wat...\n",
       "24972    post contain spoilers br year series end wb cu...\n",
       "24973    scale negative happy seeing sushmita sen nice ...\n",
       "24974    surprise mention version film share footage id...\n",
       "24975    good hollywoodish odyssey suspense terror tell...\n",
       "24976    want read comment leave review majority defina...\n",
       "24977    vampire bat definitely interest early genre se...\n",
       "24978    huge fan original cartoon series look forward ...\n",
       "24979    basu co direct flop hai debut film br film ahe...\n",
       "24980    ruth real life philanthropic gesture help ente...\n",
       "24981    clearly intelligent sensitive man bold new ide...\n",
       "24982    ignore person review admit fall asleep wonder ...\n",
       "24983    good imaginative production refreshingly free ...\n",
       "24984    old highly rate version nicholas cage fan way ...\n",
       "24985    movie amateurish kosher slaughter scene play u...\n",
       "24986    video nasties guise digital wide screen big bu...\n",
       "24987    movie stupid simply corner ridiculous want wat...\n",
       "24988    understand reviewer documentary political reas...\n",
       "24989    commitment fever pitch trick believe baseball ...\n",
       "24990    ahead want recommend film people truly begin s...\n",
       "24991    tina fey soon movie start know end sure funny ...\n",
       "24992    flick log accidentally night television miss h...\n",
       "24993    film terrible terrible waste minute life speci...\n",
       "24994    dumb movie maybe judgment harsh film promise f...\n",
       "24995    watch crap load movie vary degree quality sure...\n",
       "24996    read review defend film low budget cgi monster...\n",
       "24997    classic directorial feature police story influ...\n",
       "24998    disney old men spin classic fairy tale cindere...\n",
       "24999    ho homicidal maniac spirit tour de force adapt...\n",
       "Name: cleaned, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
