{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_vectors_web_lg\n",
    "nlp = en_vectors_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS_IN_SENTENCE = 300\n",
    "LIMIT = -1\n",
    "dataset_id = 'imdb_{}'.format(LIMIT if LIMIT > 0 else 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from shared.data import load_imdb\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "X_train, y_train = load_imdb('../data/aclImdb/train', limit=LIMIT)\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "# lower text count, because of memory problems when trying to load all\n",
    "test_limit = LIMIT if 0 <= LIMIT <= 1000 else 1000\n",
    "X_test, y_test = load_imdb('../data/aclImdb/test', limit=test_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Data sample"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"Dan Katzir has produced a wonderful film tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'If you want Scream or anything like the big-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"Outlandish premise that rates low on plausib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Let\\'s face it-- if you rented a STDVD seque...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'Bizarre Tobe Hooper exercise regarding an un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'Well, maybe the PC version of this game was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'Watching \"Kroko\" I would have liked to leave...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b\"First of all, I have to start this comment b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b\"Very much a film from the times -- extremely...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'\"The Invisible Ray\" is part science fiction ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  y\n",
       "0  b\"Dan Katzir has produced a wonderful film tha...  1\n",
       "1  b'If you want Scream or anything like the big-...  1\n",
       "2  b\"Outlandish premise that rates low on plausib...  0\n",
       "3  b'Let\\'s face it-- if you rented a STDVD seque...  0\n",
       "4  b'Bizarre Tobe Hooper exercise regarding an un...  0\n",
       "5  b'Well, maybe the PC version of this game was ...  0\n",
       "6  b'Watching \"Kroko\" I would have liked to leave...  0\n",
       "7  b\"First of all, I have to start this comment b...  1\n",
       "8  b\"Very much a film from the times -- extremely...  0\n",
       "9  b'\"The Invisible Ray\" is part science fiction ...  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Text stats"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count                                                 25000\n",
       "unique                                                24904\n",
       "top       b\"This show comes up with interesting location...\n",
       "freq                                                      3\n",
       "Name: X, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Words length stats"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       233.776720\n",
       "std        173.715418\n",
       "min         10.000000\n",
       "25%        127.000000\n",
       "50%        174.000000\n",
       "75%        284.000000\n",
       "max       2470.000000\n",
       "Name: X, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Labels stats"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    25000.00000\n",
       "mean         0.50000\n",
       "std          0.50001\n",
       "min          0.00000\n",
       "25%          0.00000\n",
       "50%          0.50000\n",
       "75%          1.00000\n",
       "max          1.00000\n",
       "Name: y, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Labels counts"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: y, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: y, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Train count: 25000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Test count:  1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from machine_learning.plot_helpers import describe_data\n",
    "\n",
    "describe_data(X_train, y_train)\n",
    "\n",
    "display_markdown('### Train count: {}'.format(len(X_train)), raw=True)\n",
    "display_markdown('### Test count:  {}'.format(len(X_test)), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Training or loading model"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Unable to load model, training...\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 22s 112ms/step - loss: 0.3000 - acc: 0.7361\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 0.2125 - acc: 0.84251s - loss: 0.2132 - a\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 22s 112ms/step - loss: 0.1832 - acc: 0.8663\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 22s 111ms/step - loss: 0.1615 - acc: 0.8789\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 22s 112ms/step - loss: 0.1445 - acc: 0.8919\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 22s 111ms/step - loss: 0.1319 - acc: 0.8986\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 22s 111ms/step - loss: 0.1241 - acc: 0.9027\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 22s 111ms/step - loss: 0.1163 - acc: 0.9079\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 22s 112ms/step - loss: 0.1106 - acc: 0.9122\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 22s 111ms/step - loss: 0.1057 - acc: 0.9176\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 22s 111ms/step - loss: 0.1035 - acc: 0.9212\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0993 - acc: 0.9261\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0993 - acc: 0.9253\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0961 - acc: 0.9309\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0941 - acc: 0.9336\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 0.0947 - acc: 0.9339\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 0.0917 - acc: 0.9375\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 20s 105ms/step - loss: 0.0901 - acc: 0.9392\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0906 - acc: 0.9410\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0901 - acc: 0.9413\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0916 - acc: 0.9394\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0893 - acc: 0.9432\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.0872 - acc: 0.9444\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 20s 104ms/step - loss: 0.0874 - acc: 0.9447\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 18s 92ms/step - loss: 0.0867 - acc: 0.9461\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0863 - acc: 0.9451\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0844 - acc: 0.9484\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0856 - acc: 0.9488\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0852 - acc: 0.9483\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0851 - acc: 0.9475\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0836 - acc: 0.9507\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0835 - acc: 0.9499\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0828 - acc: 0.9514\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 12s 62ms/step - loss: 0.0824 - acc: 0.9515\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 12s 63ms/step - loss: 0.0825 - acc: 0.9510\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 0.0824 - acc: 0.9515\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 0.0824 - acc: 0.9513\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0816 - acc: 0.9514\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0807 - acc: 0.9523\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0810 - acc: 0.9544\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0786 - acc: 0.9561\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 12s 64ms/step - loss: 0.0793 - acc: 0.9536\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0789 - acc: 0.9549\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 0.0788 - acc: 0.9553\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0782 - acc: 0.9555\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0774 - acc: 0.9563\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0777 - acc: 0.9561\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 13s 64ms/step - loss: 0.0770 - acc: 0.9563\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 12s 63ms/step - loss: 0.0778 - acc: 0.9559\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 12s 64ms/step - loss: 0.0770 - acc: 0.9560\n",
      "Model 'keras_imdb_all_999bd479.h5' saved\n"
     ]
    }
   ],
   "source": [
    "from shared.models import KerasModel\n",
    "from machine_learning.plot_helpers import plot_training\n",
    "\n",
    "display_markdown('#### Training or loading model', raw=True)\n",
    "\n",
    "model = KerasModel(\n",
    "    nlp, dataset_id, max_words_in_sentence=MAX_WORDS_IN_SENTENCE, \n",
    "    epochs=50)\n",
    "\n",
    "try:\n",
    "    print(\"Loading model...\")\n",
    "    model.load()\n",
    "    print(\"Model '{}' loaded\".format(model.filename))\n",
    "except IOError:\n",
    "    print(\"Unable to load model, training...\")\n",
    "    history = model.train(X_train, y_train)\n",
    "    model.save()\n",
    "    print(\"Model '{}' saved\".format(model.filename))\n",
    "    plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Overview of created convolutional network architecture"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 296, 32)           48032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 59, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 59, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 55, 64)            10304     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 58,785\n",
      "Trainable params: 58,593\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(\"#### Overview of created convolutional network architecture\", raw=True)\n",
    "\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Raw text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'This movie is, in my opinion, very worth watching!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I kinda liked that movie. Maybe it's not as good as other, but still watchable\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I have to warn everybody, this movie is really bad. Actors don't know how to play. It su!*!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Cleaned text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'this movie is in my opinion very worth watching!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"i kinda liked that movie maybe it's not as good as other but still watchable\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"i have to warn everybody this movie is really bad actors don't know how to play it su! !\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Predicted scores"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957330</td>\n",
       "      <td>This movie is, in my opinion, very worth watching!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718341</td>\n",
       "      <td>I kinda liked that movie. Maybe it's not as good as other, but still watchable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>I have to warn everybody, this movie is really bad. Actors don't know how to play. It su!*!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  \\\n",
       "0  0.957330   \n",
       "1  0.718341   \n",
       "2  0.000038   \n",
       "\n",
       "                                                                                          text  \n",
       "0  This movie is, in my opinion, very worth watching!                                           \n",
       "1  I kinda liked that movie. Maybe it's not as good as other, but still watchable               \n",
       "2  I have to warn everybody, this movie is really bad. Actors don't know how to play. It su!*!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import pipeline\n",
    "from shared import transformers\n",
    "\n",
    "raw_samples = np.array([\n",
    "    \"This movie is, in my opinion, very worth watching!\",\n",
    "    \"I kinda liked that movie. Maybe it's not as good as other, but still watchable\",\n",
    "    \"I have to warn everybody, this movie is really bad. Actors don't know how to play. It su!*!\",\n",
    "], dtype='object')\n",
    "\n",
    "display_markdown(\"#### Raw text\", raw=True)\n",
    "\n",
    "for text in raw_samples:\n",
    "    display(text)\n",
    "\n",
    "display_markdown(\"#### Cleaned text\", raw=True)\n",
    "\n",
    "clear_pipeline = pipeline.Pipeline([\n",
    "    ('clear', transformers.ClearTextTransformer()),\n",
    "])\n",
    "\n",
    "for text in clear_pipeline.transform(raw_samples):\n",
    "    display(text)\n",
    "\n",
    "display_markdown(\"#### Predicted scores\", raw=True)\n",
    "with pd.option_context(\"display.max_colwidth\", -1):\n",
    "    display(pd.DataFrame({\n",
    "        \"text\": pd.Series(raw_samples),\n",
    "        \"score\": pd.Series(model.predict_proba(raw_samples)[:, 1].reshape(len(raw_samples))),\n",
    "    }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from machine_learning.evaluation import evaluate_and_report\n",
    "evaluate_and_report(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
